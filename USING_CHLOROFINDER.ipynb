{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMVzEW4EI6+ZoQLVfPklCcQ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwasswa2023/ChloroFinder/blob/main/USING_CHLOROFINDER.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f6ZevKV_jBML"
      },
      "outputs": [],
      "source": [
        "!pip install pyteomics\n",
        "!pip install joblib\n",
        "\n",
        "\n",
        "import os, ast\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from itertools import combinations\n",
        "from scipy.sparse import csr_matrix, hstack\n",
        "import joblib\n",
        "from pyteomics import mzml  # pip install pyteomics\n",
        "\n",
        "# =========================\n",
        "# CONFIG\n",
        "# =========================\n",
        "INPUT_CSV  = \"/Your_MS2_fragments.csv\"\n",
        "MZML_PATH  = \"/Your_mzml_file.mzML\"\n",
        "MODEL_PATH = \"/ChloroFinder.pkl\"\n",
        "\n",
        "OUT_ALL    = \"/content/mgf_predictions_all_with_isotopes.csv\"\n",
        "OUT_POS    = \"/content/mgf_predictions_chlorinated_only_with_isotopes.csv\"\n",
        "\n",
        "# Model feature building (match training)\n",
        "ROUND_DP   = 3\n",
        "MIN_DELTA  = 0.001\n",
        "MAX_DELTA  = None\n",
        "\n",
        "# Isotope inspection (MS1)\n",
        "ISOTOPE_BIN_DA = 0.01\n",
        "CL_M2_SHIFT    = 1.99705\n",
        "CL_M4_SHIFT    = 3.99410\n",
        "ISOTOPE_TAU    = 0.12\n",
        "CL_EXPECTED_RATIOS = {1: 0.32, 2: 0.60, 3: 0.90}\n",
        "EPS = 1e-12\n",
        "\n",
        "# MS2 fragment isotope pairing\n",
        "MS2_PAIR_TOL_DA = 0.01\n",
        "\n",
        "# CSV column names\n",
        "MZ_COL        = \"mz_values\"\n",
        "INT_COL       = \"intensity_values\"\n",
        "RT_COL        = \"RTINSECONDS\"\n",
        "PRECURSOR_COL = \"PEPMASS\"\n",
        "\n",
        "# ======= FUSION: weights & thresholds =======\n",
        "W_MODEL   = 0.6    # weight for model probability\n",
        "W_MS1ISO  = 0.35   # weight for MS1 isotope score (0..1)\n",
        "W_MS2PAIR = 0.05   # small bonus if any fragment has +1.997 partner\n",
        "FINAL_THRESHOLD = 0.60   # combined_score >= this => chlorinated\n",
        "\n",
        "# (Optional) guardrails — if you want hard minimums in addition to the fused score\n",
        "MIN_MODEL_PROB = 0.0     # e.g., 0.30; keep 0 to rely purely on fused score\n",
        "MIN_ISO_SCORE  = 0.0     # e.g., 0.30; keep 0 to rely purely on fused score\n",
        "\n",
        "# =========================\n",
        "# HELPERS\n",
        "# =========================\n",
        "def safe_parse_list(x):\n",
        "    if isinstance(x, list):\n",
        "        return x\n",
        "    if pd.isna(x):\n",
        "        return []\n",
        "    s = str(x).strip()\n",
        "    try:\n",
        "        val = ast.literal_eval(s)\n",
        "        if isinstance(val, (list, tuple)):\n",
        "            return [float(v) for v in val]\n",
        "    except Exception:\n",
        "        pass\n",
        "    try:\n",
        "        parts = [p.strip() for p in s.strip(\"[]() \").split(\",\") if p.strip()]\n",
        "        return [float(p) for p in parts]\n",
        "    except Exception:\n",
        "        return []\n",
        "\n",
        "def round_unique(values, dp=3):\n",
        "    out, seen = [], set()\n",
        "    for v in values:\n",
        "        rv = round(float(v), dp)\n",
        "        if rv not in seen:\n",
        "            seen.add(rv); out.append(rv)\n",
        "    return out\n",
        "\n",
        "def compute_delta_mz_list(frag_list, round_dp=3, min_delta=0.001, max_delta=None):\n",
        "    if not frag_list or len(frag_list) < 2:\n",
        "        return []\n",
        "    frags = sorted(set(float(f) for f in frag_list))\n",
        "    deltas = []\n",
        "    for a, b in combinations(frags, 2):\n",
        "        d = abs(a - b)\n",
        "        if d < min_delta: continue\n",
        "        if (max_delta is not None) and (d > max_delta): continue\n",
        "        deltas.append(round(d, round_dp))\n",
        "    return sorted(set(deltas))\n",
        "\n",
        "def get_rt_minutes(spec):\n",
        "    return float(spec['scanList']['scan'][0].get('scan start time', np.nan))\n",
        "\n",
        "def build_ms1_cache(mzml_path):\n",
        "    cache = []\n",
        "    with mzml.MzML(mzml_path) as r:\n",
        "        for spec in r:\n",
        "            if spec.get('ms level') == 1:\n",
        "                rt = get_rt_minutes(spec)\n",
        "                unit = spec['scanList']['scan'][0].get('scan start time unit', '').lower()\n",
        "                if 'second' in unit:\n",
        "                    rt_seconds = rt\n",
        "                else:\n",
        "                    rt_seconds = rt * 60.0\n",
        "                ms1_mz = spec['m/z array'].astype(float)\n",
        "                ms1_int = spec['intensity array'].astype(float)\n",
        "                cache.append((rt_seconds, ms1_mz, ms1_int))\n",
        "    return cache\n",
        "\n",
        "def nearest_ms1(ms1_cache, rt_seconds):\n",
        "    if not ms1_cache:\n",
        "        return np.array([]), np.array([])\n",
        "    rts = np.array([t[0] for t in ms1_cache], dtype=float)\n",
        "    i = int(np.argmin(np.abs(rts - rt_seconds)))\n",
        "    return ms1_cache[i][1], ms1_cache[i][2]\n",
        "\n",
        "def integrate_peak(ms1_mz, ms1_int, target_mz, bin_da=ISOTOPE_BIN_DA):\n",
        "    if ms1_mz.size == 0:\n",
        "        return 0.0\n",
        "    mask = (ms1_mz >= target_mz - bin_da) & (ms1_mz <= target_mz + bin_da)\n",
        "    return float(np.sum(ms1_int[mask])) if np.any(mask) else 0.0\n",
        "\n",
        "def ms1_isotope_metrics(ms1_mz, ms1_int, precursor_mz):\n",
        "    M  = integrate_peak(ms1_mz, ms1_int, precursor_mz, ISOTOPE_BIN_DA)\n",
        "    M2 = integrate_peak(ms1_mz, ms1_int, precursor_mz + CL_M2_SHIFT, ISOTOPE_BIN_DA)\n",
        "    M4 = integrate_peak(ms1_mz, ms1_int, precursor_mz + CL_M4_SHIFT, ISOTOPE_BIN_DA)\n",
        "    ratio = (M2 / (M + EPS)) if M > 0 else 0.0\n",
        "    best, best_n = 0.0, 0\n",
        "    for n, exp_r in CL_EXPECTED_RATIOS.items():\n",
        "        sc = float(np.exp(-abs(ratio - exp_r) / ISOTOPE_TAU))\n",
        "        if sc > best:\n",
        "            best, best_n = sc, n\n",
        "    return M, M2, M4, ratio, best, best_n\n",
        "\n",
        "def ms2_fragment_isotope_pairs(frag_mz_list, tol_da=MS2_PAIR_TOL_DA, shift=CL_M2_SHIFT, max_pairs_to_show=5):\n",
        "    if not frag_mz_list:\n",
        "        return 0, \"\"\n",
        "    mzs = sorted(set(float(round(m, 3)) for m in frag_mz_list))\n",
        "    mzs_arr = np.array(mzs)\n",
        "    pairs = []\n",
        "    for m in mzs:\n",
        "        target = m + shift\n",
        "        idx = np.argmin(np.abs(mzs_arr - target))\n",
        "        if abs(mzs_arr[idx] - target) <= tol_da:\n",
        "            pairs.append((m, float(mzs_arr[idx])))\n",
        "    pairs = sorted(set(pairs))\n",
        "    ex_str = \"; \".join([f\"{a:.3f}->{b:.3f}\" for a,b in pairs[:max_pairs_to_show]])\n",
        "    return len(pairs), ex_str\n",
        "\n",
        "# =========================\n",
        "# LOAD MODEL + ENCODERS\n",
        "# =========================\n",
        "bundle    = joblib.load(MODEL_PATH)\n",
        "model     = bundle[\"model\"]\n",
        "mlb_frag  = bundle[\"mlb_frag\"]\n",
        "mlb_delta = bundle[\"mlb_delta\"]\n",
        "\n",
        "# =========================\n",
        "# LOAD DATA\n",
        "# =========================\n",
        "df = pd.read_csv(INPUT_CSV)\n",
        "df[MZ_COL]  = df[MZ_COL].apply(safe_parse_list)\n",
        "df[INT_COL] = df[INT_COL].apply(safe_parse_list)\n",
        "\n",
        "# Features to match training\n",
        "df[\"frag_list\"]  = df[MZ_COL].apply(lambda xs: round_unique(xs, dp=ROUND_DP))\n",
        "df[\"delta_list\"] = df[\"frag_list\"].apply(lambda frags: compute_delta_mz_list(frags, round_dp=ROUND_DP,\n",
        "                                                                            min_delta=MIN_DELTA, max_delta=MAX_DELTA))\n",
        "\n",
        "# Transform with trained encoders\n",
        "X_frag  = csr_matrix(mlb_frag.transform(df[\"frag_list\"]), dtype=np.float32)\n",
        "X_delta = csr_matrix(mlb_delta.transform(df[\"delta_list\"]), dtype=np.float32)\n",
        "X       = hstack([X_frag, X_delta], format=\"csr\").astype(np.float32)\n",
        "\n",
        "# Model predictions\n",
        "y_prob = model.predict_proba(X)[:, 1]\n",
        "\n",
        "# =========================\n",
        "# MS1 + MS2 ISOTOPE EVIDENCE\n",
        "# =========================\n",
        "if not os.path.isfile(MZML_PATH):\n",
        "    raise FileNotFoundError(f\"mzML not found at: {MZML_PATH}\")\n",
        "\n",
        "print(\"Caching MS1 from mzML…\")\n",
        "ms1_cache = build_ms1_cache(MZML_PATH)\n",
        "print(f\"  cached {len(ms1_cache)} MS1 spectra\")\n",
        "\n",
        "# ensure RT in seconds\n",
        "if df[RT_COL].max() < 100:\n",
        "    df[\"_rt_seconds\"] = df[RT_COL] * 60.0\n",
        "else:\n",
        "    df[\"_rt_seconds\"] = df[RT_COL].astype(float)\n",
        "\n",
        "ms1_M_list, ms1_M2_list, ms1_M4_list = [], [], []\n",
        "ms1_ratio_list, ms1_iso_score_list, ms1_bestN_list = [], [], []\n",
        "ms2_pair_count_list, ms2_pair_examples_list = [], []\n",
        "\n",
        "for _, row in df.iterrows():\n",
        "    rt_sec = float(row[\"_rt_seconds\"])\n",
        "    prec_mz = float(row[PRECURSOR_COL])\n",
        "\n",
        "    ms1_mz, ms1_int = nearest_ms1(ms1_cache, rt_sec)\n",
        "    M, M2, M4, ratio, iso_score, bestN = ms1_isotope_metrics(ms1_mz, ms1_int, prec_mz)\n",
        "    ms1_M_list.append(M);   ms1_M2_list.append(M2); ms1_M4_list.append(M4)\n",
        "    ms1_ratio_list.append(ratio); ms1_iso_score_list.append(iso_score); ms1_bestN_list.append(bestN)\n",
        "\n",
        "    cnt, ex = ms2_fragment_isotope_pairs(row[\"frag_list\"], tol_da=MS2_PAIR_TOL_DA, shift=CL_M2_SHIFT)\n",
        "    ms2_pair_count_list.append(cnt); ms2_pair_examples_list.append(ex)\n",
        "\n",
        "# =========================\n",
        "# FUSED DECISION\n",
        "# =========================\n",
        "# Normalize MS2 evidence to {0,1} as “any Cl-like pair?”\n",
        "ms2_evidence = np.array([1 if c > 0 else 0 for c in ms2_pair_count_list], dtype=float)\n",
        "\n",
        "# Combine\n",
        "y_prob_arr   = np.array(y_prob, dtype=float)\n",
        "iso_arr      = np.array(ms1_iso_score_list, dtype=float)\n",
        "combined     = W_MODEL*y_prob_arr + W_MS1ISO*iso_arr + W_MS2PAIR*ms2_evidence\n",
        "\n",
        "# Optional guardrails (keep them 0.0 to disable)\n",
        "meets_min = (y_prob_arr >= MIN_MODEL_PROB) & (iso_arr >= MIN_ISO_SCORE)\n",
        "combined_pred = (combined >= FINAL_THRESHOLD) & meets_min\n",
        "combined_pred = combined_pred.astype(int)\n",
        "\n",
        "# =========================\n",
        "# OUTPUT\n",
        "# =========================\n",
        "df_out = df.copy()\n",
        "df_out[\"chlorinated_probability\"] = y_prob_arr\n",
        "df_out[\"ms1_M\"]            = ms1_M_list\n",
        "df_out[\"ms1_M2\"]           = ms1_M2_list\n",
        "df_out[\"ms1_M4\"]           = ms1_M4_list\n",
        "df_out[\"ms1_M2_over_M\"]    = ms1_ratio_list\n",
        "df_out[\"ms1_iso_score\"]    = iso_arr\n",
        "df_out[\"ms1_best_nCl_like\"]= ms1_bestN_list\n",
        "df_out[\"ms2_cl_pairs_count\"]   = ms2_pair_count_list\n",
        "df_out[\"ms2_cl_pairs_examples\"]= ms2_pair_examples_list\n",
        "\n",
        "df_out[\"combined_score\"] = combined\n",
        "df_out[\"combined_pred\"]  = combined_pred\n",
        "\n",
        "df_out.to_csv(OUT_ALL, index=False)\n",
        "\n",
        "df_pos = df_out[df_out[\"combined_pred\"] == 1].copy()\n",
        "df_pos.to_csv(OUT_POS, index=False)\n",
        "\n",
        "print(f\"✅ Wrote full predictions + fused decision: {OUT_ALL}\")\n",
        "print(f\"✅ Wrote chlorinated-only (fused): {OUT_POS}\")\n",
        "try:\n",
        "    print(df_pos.head(10)[[\"FEATURE_ID\",\"RTINSECONDS\",\"PEPMASS\",\n",
        "                           \"chlorinated_probability\",\"ms1_iso_score\",\n",
        "                           \"ms2_cl_pairs_count\",\"combined_score\",\"combined_pred\"]])\n",
        "except Exception:\n",
        "    pass\n"
      ]
    }
  ]
}