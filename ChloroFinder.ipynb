{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOVcjg1A+wTIsAVy973Bo8x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jwasswa2023/ChloroFinder/blob/main/ChloroFinder.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t4Af2H58j-3l"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from itertools import combinations\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold\n",
        "from sklearn.preprocessing import MultiLabelBinarizer\n",
        "from sklearn.metrics import (\n",
        "    classification_report, confusion_matrix, f1_score,\n",
        "    balanced_accuracy_score, matthews_corrcoef, roc_auc_score,\n",
        "    accuracy_score\n",
        ")\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from collections import Counter\n",
        "from scipy.sparse import hstack, csr_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import joblib\n",
        "\n",
        "# ----------------------------\n",
        "# Load cleaned data\n",
        "# ----------------------------\n",
        "df = pd.read_csv('fragments_cleaned_and_parsed.csv')\n",
        "# ensure frag_list is a list\n",
        "df['frag_list'] = df['frag_list'].apply(lambda x: x if isinstance(x, list) else eval(x))\n",
        "y = df['chlorinated'].astype(int).values\n",
        "\n",
        "# ----------------------------\n",
        "# Helper: compute Œîm/z features\n",
        "# ----------------------------\n",
        "def compute_delta_mz_list(frag_list, round_dp=3, min_delta=0.001, max_delta=None):\n",
        "    if not frag_list or len(frag_list) < 2:\n",
        "        return []\n",
        "    frags = sorted(set(float(f) for f in frag_list))\n",
        "    deltas = []\n",
        "    for a, b in combinations(frags, 2):\n",
        "        d = abs(a - b)\n",
        "        if d < min_delta:\n",
        "            continue\n",
        "        if max_delta is not None and d > max_delta:\n",
        "            continue\n",
        "        deltas.append(round(d, round_dp))\n",
        "    return sorted(set(deltas))\n",
        "\n",
        "# ----------------------------\n",
        "# Build feature spaces\n",
        "# ----------------------------\n",
        "# 1) fragment presence (multi-hot)\n",
        "mlb_frag = MultiLabelBinarizer()\n",
        "X_frag = mlb_frag.fit_transform(df['frag_list'])\n",
        "X_frag = csr_matrix(X_frag, dtype=np.float32)\n",
        "\n",
        "# 2) delta-m/z presence (multi-hot)\n",
        "delta_lists = df['frag_list'].apply(lambda frags: compute_delta_mz_list(frags, round_dp=3))\n",
        "mlb_delta = MultiLabelBinarizer()\n",
        "X_delta = mlb_delta.fit_transform(delta_lists)\n",
        "X_delta = csr_matrix(X_delta, dtype=np.float32)\n",
        "\n",
        "# Combine\n",
        "X = hstack([X_frag, X_delta], format='csr').astype(np.float32)\n",
        "\n",
        "print(f\"Fragments feature dim: {X_frag.shape[1]}\")\n",
        "print(f\"Delta-m/z feature dim: {X_delta.shape[1]}\")\n",
        "print(f\"Total feature dim:     {X.shape[1]}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Train / Test Split (stratified)\n",
        "# ----------------------------\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.20, stratify=y, random_state=42\n",
        ")\n",
        "\n",
        "# Optional: quick class distribution check\n",
        "counts = Counter(y_train)\n",
        "print(f\"Train class counts: {counts}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Random Forest + Grid Search\n",
        "# ----------------------------\n",
        "# Note: for classification, valid criteria are 'gini', 'entropy', 'log_loss'\n",
        "param_grid = {\n",
        "    \"n_estimators\": [50, 100, 150, 200, 300],\n",
        "    \"max_depth\": [None, 5, 10, 20, 50],\n",
        "    \"min_samples_split\": [2, 5, 10],\n",
        "    \"min_samples_leaf\": [1, 2, 4],\n",
        "    \"bootstrap\": [True, False]\n",
        "}\n",
        "\n",
        "base_model = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    n_jobs=-1,            # parallelize across CPU cores\n",
        "    class_weight=None     # set to 'balanced' if your classes are very imbalanced\n",
        ")\n",
        "\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "grid = GridSearchCV(\n",
        "    base_model,\n",
        "    param_grid,\n",
        "    scoring='f1',         # you can switch to 'f1_macro' if classes are imbalanced\n",
        "    cv=cv,\n",
        "    verbose=1,\n",
        "    n_jobs=-1\n",
        ")\n",
        "\n",
        "print(\"üîç Starting Grid Search (Random Forest)...\")\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "# ----------------------------\n",
        "# Best model & evaluation\n",
        "# ----------------------------\n",
        "best_model = grid.best_estimator_\n",
        "print(\"\\n Best Parameters:\")\n",
        "print(grid.best_params_)\n",
        "\n",
        "y_pred = best_model.predict(X_test)\n",
        "y_prob = best_model.predict_proba(X_test)[:, 1]  # available when criterion != 'entropy'? (RF provides proba for all)\n",
        "\n",
        "print(\"\\nüìä Classification Report:\")\n",
        "print(classification_report(y_test, y_pred))\n",
        "\n",
        "acc = accuracy_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "ba = balanced_accuracy_score(y_test, y_pred)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "\n",
        "print(f\" Accuracy: {acc:.3f}\")\n",
        "print(f\" F1 Score: {f1:.3f}\")\n",
        "print(f\" Balanced Accuracy: {ba:.3f}\")\n",
        "print(f\" MCC: {mcc:.3f}\")\n",
        "print(f\" ROC-AUC: {roc_auc:.3f}\")\n",
        "\n",
        "# ----------------------------\n",
        "# Confusion Matrix\n",
        "# ----------------------------\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "            xticklabels=['Non-Chlorinated', 'Chlorinated'],\n",
        "            yticklabels=['Non-Chlorinated', 'Chlorinated'])\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix (Random Forest)')\n",
        "plt.show()\n",
        "\n",
        "# ----------------------------\n",
        "# Save model + encoders\n",
        "# ----------------------------\n",
        "joblib.dump({\n",
        "    'model': best_model,\n",
        "    'mlb_frag': mlb_frag,\n",
        "    'mlb_delta': mlb_delta\n",
        "}, 'ChloroFinder.pkl')\n",
        "print(\" Saved model + encoders to 'ChloroFinder.pkl'\")"
      ]
    }
  ]
}